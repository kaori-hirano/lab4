---
title: "Lab 4: PCA and Clustering"
author: "Kaori Hirano"
date: "6/29/23"
format: pdf
---

# Packages

```{r load-packages}
# load packages here
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(readr))
library(ISLR2)
library(broom) # for tidy function
library(patchwork) # for plot placement
library(ggdendro) # for dendrograms
library(mdsr) # for later examples
```

# Data  

```{r load-data}
# load data here
load("data/vendor_data.RData")
```


# Data Wrangling

## Q1 
First, let’s fix a small issue and create a new, categorical version of income.
1. One particular respondent reported owning 80,000 houses. This is most likely untrue
(and seriously affects the standard deviation, which, as you know from the reading and
the example code, plays a key role in PCA in particular). Let’s replace this value with
NA.
2. Use the cut_number() function on the income variable to create a 10-level version of
this variable. Call this hh_income_cat10
```{r q1}
vendor_data$houses[vendor_data$houses == 80000] <- NA # replaces likely mistake with NA

# summary(vendor_data$houses) checks if works
vendor_data$hh_income_cat10 <- cut_number(vendor_data$hh_income_trim_99, 10) # cuts income into 10 groups
```

# PCA
### Q2
What are the mean and variance of the possessions variables? Does it seem like we should
scale them before doing PCA?
```{r q2}
# prints means and variances for all posession variables
cbind(mean(vendor_data$houses, na.rm = TRUE), var(vendor_data$houses, na.rm= TRUE))

cbind(mean(vendor_data$acres_farmland, na.rm = TRUE), var(vendor_data$acres_farmland, na.rm= TRUE))

cbind(mean(vendor_data$bicycles, na.rm = TRUE), var(vendor_data$bicycles, na.rm= TRUE))

cbind(mean(vendor_data$chickens, na.rm = TRUE), var(vendor_data$chickens, na.rm= TRUE))

cbind(mean(vendor_data$goats, na.rm = TRUE), var(vendor_data$goats, na.rm= TRUE))

cbind(mean(vendor_data$basic_cell_phones, na.rm = TRUE), var(vendor_data$basic_cell_phones, na.rm= TRUE))

cbind(mean(vendor_data$smart_phones, na.rm = TRUE), var(vendor_data$smart_phones, na.rm= TRUE))


# drops all nas for simplicity's sake
vdrm <- drop_na(vendor_data)
apply(vdrm[, 12:18], 2, mean) # we need to subset to columns 2 through 5 
                                # because first column is character column
apply(vdrm[, 12:18], 2, var)
```
NEEDS INTERPRETATIONS WITH SHOULD WE REDO THE VARIANCE OR WHATEVS

### Q3
Use the prcomp() function to do PCA. Create two scree plots like the ones in Figure 12.3 of
the textbook. Is there an elbow? How many components does it seem are sufficient?
```{r q3}
pr_vd <- prcomp(vdrm[, 12:18], scale = TRUE) 
# pr_vd

comp_vd <- pr_vd$x %>% 
  as_tibble()

pve_vd <- tibble(component = 1:ncol(comp_vd),
              var = pr_vd$sdev^2,
              pve = var/sum(var),
              cumulative = cumsum(pve))

#summary(pr_out)$importance[2, ]

## cumulative pve
#summary(pr_out)$importance[3, ]


pve_vd_plot <- ggplot(pve_vd) +
  geom_point(aes(x = component,
                 y = pve),
             color = "blue",
             shape = 1) +
  geom_line(aes(x = component,
                y = pve), 
            color = "blue") +
  labs(x = "Principal Component",
       y = "Proportion of Variance Explained") +
  theme_classic()

cpve_vd_plot <- ggplot(pve_vd) +
  geom_point(aes(x = component,
                 y = cumulative),
             color = "brown3") +
  geom_line(aes(x = component,
                y = cumulative),
             color = "brown3") +
  labs(x = "Principal Component",
       y = "Cumulative Proportion of Variance Explained") +
  ylim(c(0, 1)) +
  theme_classic()  

# using patchwork package again
pve_vd_plot + cpve_vd_plot
```
There is an elbow. 3 components seems to be sufficient. 

### Q4
Plot each of these components (the optimal number based on Q3) against household income.
Arrange the plots using the patchwork package as demonstrated in this module’s example
code. Which component(s) seem to proxy for income, if any?
```{r q4}



```


# Clustering
### Q5
Use kmeans() with 𝐾 = 10. Set the seed to 67 beforehand and use 30 different starting
points.
Then do the following:
1. Report the average possession variables in each of the ten groups.
2. Calculate the average household income within each category.
3. Visualize or show in some way the concordance between the hh_income_cat10 variable
and the 10 clusters (such as a cross tab or mosaic plot).
Finally, report on how well the clustering worked to approximate income groups. Put the 10
clusters into order from least wealthy to most wealth and explain why you chose that order.
```{r q5-set-up}
#sets seed
set.seed(67)

# subsets so only numerical possessive are included
vd_pos <- vdrm[, 12:18]

# k means
km_out <- kmeans(vd_pos, 10, nstart = 30)
```

1. Report the average possession variables in each of the ten groups.
```{r q5-p1}
# gets cluster assignment for each point
(km_clusters <- km_out$cluster)

# need to group by cluster
vd_pos$cluster <- km_clusters

# then compute the avg of cluster by cluster col

```
2. Calculate the average household income within each category.
```{r q5-p2}

```
3. Visualize or show in some way the concordance between the hh_income_cat10 variable
and the 10 clusters (such as a cross tab or mosaic plot).
```{r q5-p3}

```
### Q6
Repeat the previous, but this time use hierarchical clustering with average linkage. Cut the
tree a 10 clusters. Answer the same three questions.
Finally: is there any overlap between the clusters created through hierarchical clustering and
the clusters created using 𝐾-means?
Note: If focusing on prediction, we could use cross-validation to try to see which linkage
approach works best, as the section on clustering in ISLR points out. We’ll talk more about
that during the homework for this module

```{r q6-set-up, fig.height = 10, fig.width = 10}
#| warning = FALSE

# gets rid of nas in response
vendor_data_rm <- drop_na(vendor_data)
# remember not to scale because of instructions

# sets up distances
data_dist <- dist(vendor_data_rm)

# clusters 
al_nci <- hclust(data_dist, method = "average") %>% 
  ggdendrogram() +
  labs(title = "Average Linkage")

# cuts tree into 10 clusters
hc_out <- hclust(dist(vendor_data_rm))
hc_clusters <- cutree(hc_out, 10)
table(hc_clusters)
```
1. Report the average possession variables in each of the ten groups.
```{r q6-p1}
vd_pos$hc_clusters <- hc_clusters

(houses <- with(vd_pos, tapply(houses, hc_clusters, mean))
```
2. Calculate the average household income within each category.
```{r q6-p2}

```
3. Visualize or show in some way the concordance between the hh_income_cat10 variable
and the 10 clusters (such as a cross tab or mosaic plot).
```{r q6-p3}

```

4. is there any overlap between the clusters created through hierarchical clustering and
the clusters created using 𝐾-means?
```{r q6-p4}

```